# CamVid Dataset PyTorch DataLoader

Complete PyTorch dataloader implementation for the CamVid semantic segmentation dataset with 11 classes.

## Data Download
You can find the raw images and labeled images at here: [CamVid](https://datasets.cms.waikato.ac.nz/ufdl/camvid/)

## Dataset Structure

```
/data/CamVid/
├── 701_StillsRaw_full/          # Raw RGB images
├── LabeledApproved_full/         # RGB color-coded label masks (_L.png)
├── label_colors.txt              # RGB to class name mapping
└── splits/                       # Generated by prepare script
    ├── train.txt
    ├── val.txt
    ├── test.txt
    └── dataset_info.json
```

## 11-Class Grouping

Following MATLAB's SegNet methodology, the original 32 CamVid classes are grouped into 11 classes:

1. **Sky** - Sky
2. **Building** - Bridge, Building, Wall, Tunnel, Archway
3. **Pole** - Column_Pole, TrafficCone
4. **Road** - Road, LaneMkgsDriv, LaneMkgsNonDriv
5. **Pavement** - Sidewalk, ParkingBlock, RoadShoulder
6. **Tree** - Tree, VegetationMisc
7. **SignSymbol** - SignSymbol, Misc_Text, TrafficLight
8. **Fence** - Fence
9. **Car** - Car, SUVPickupTruck, Truck_Bus, Train, OtherMoving
10. **Pedestrian** - Pedestrian, Child, CartLuggagePram, Animal
11. **Bicyclist** - Bicyclist, MotorcycleScooter

The **Void** class is excluded from the 11 classes and remains as `ignore_index=255`.

This grouping provides better class balance and improved training, especially for underrepresented classes.

## Files Overview

1. **prepare_camvid_data.py** - Data preparation script
   - Scans and pairs images with labels
   - Applies 11-class grouping from original 32 classes
   - Creates train/val/test splits (70/15/15)
   - Computes dataset statistics (mean, std)
   - Computes class distribution and weights

2. **camvid_dataset.py** - PyTorch Dataset class
   - Loads images and converts RGB masks to class indices
   - Applies data augmentation (training) or just normalization (val/test)
   - Handles void/ignore class (index 255)

3. **create_camvid_dataloaders.py** - DataLoader creation
   - Creates train/val/test dataloaders
   - Configurable batch size, workers, image size
   - Returns class weights for loss function

4. **train_fcn.py** - FCN training script
   - Complete training loop with FCN model
   - Configured for 11 classes

## Usage

### Step 1: Prepare the Dataset
Symbolic link the CamVid folder to this folder. The CamVid folder must contain:
* 701\_StillsRaw\_full: The raw images
* LabeledApproved\_full: The labeled images
* label\_colors.txt: The classname mapping

```bash
ln -s /path/to/CamVid .
python prepare_camvid_data.py
```

This will create:
- `splits/train.txt` - List of training image filenames
- `splits/val.txt` - List of validation image filenames
- `splits/test.txt` - List of test image filenames
- `splits/dataset_info.json` - Metadata (11 classes, stats, weights)

### Step 2: Use in Your Training Script

```python
from create_camvid_dataloaders import create_camvid_dataloaders
import torch.nn as nn

# Create dataloaders
dataloaders = create_camvid_dataloaders(
    raw_image_dir='./CamVid/701_StillsRaw_full',
    label_dir='./CamVid/LabeledApproved_full',
    splits_dir='./CamVid/splits',
    dataset_info_path='./CamVid/splits/dataset_info.json',
    batch_size=8,
    num_workers=4,
    target_size=(480, 352)  # Resize to 480x360, then center crop to 480x352
)

train_loader = dataloaders['train']
val_loader = dataloaders['val']
test_loader = dataloaders['test']
class_weights = dataloaders['class_weights']
num_classes = dataloaders['num_classes']  # 11
ignore_index = dataloaders['ignore_index']  # 255

# Setup loss with class weights
criterion = nn.CrossEntropyLoss(
    weight=class_weights,
    ignore_index=ignore_index
)

# Training loop
for batch in train_loader:
    images = batch['image']  # [B, 3, 352, 480]
    masks = batch['mask']    # [B, 352, 480]
    filenames = batch['filename']

    # Your model forward pass
    outputs = model(images)  # [B, num_classes, 352, 480]
    loss = criterion(outputs, masks)
```

### Step 3: Usege Examples
```bash
# Normal training (from scratch)
python train_fcn.py

# Resume from last checkpoint
python train_fcn.py --resume ./models/FCNs-vgg16_batch16_epoch100_SGD_lr0.001_mom0.9_wd0.0005_last.pth

# Resume with lower learning rate (fine-tuning)
python train_fcn.py --resume ./models/FCNs-vgg16_batch16_epoch100_SGD_lr0.001_mom0.9_wd0.0005_best.pth --override-lr 1e-4

# Resume from epoch 50 checkpoint
python train_fcn.py --resume ./models/FCNs-vgg16_batch16_epoch100_SGD_lr0.001_mom0.9_wd0.0005_epoch_50.pth
```

## Key Features

### Data Augmentation (Training)
- Resize to 480x360
- Center crop to 480x352 (divisible by 32 for FCN)
- Random horizontal flip
- Color jittering (brightness, contrast, saturation, hue)
- Normalization

### Validation/Test
- Resize to 480x360
- Center crop to 480x352
- Normalization only (no augmentation)

### Class Handling
- 11 classes (grouped from original 32)
- Void class (RGB: 0,0,0) mapped to index 255
- Class weights computed for imbalanced classes

### RGB to Index Conversion
- Automatically converts RGB color masks to class indices
- Handles on-the-fly during loading
- Uses 11-class grouping mapping

## Dataset Info

- **Total classes**: 11 (grouped from 32 original classes)
- **Image size**: 480x352 (resized from original, divisible by 32)
- **Format**: RGB images + RGB color-coded masks
- **Split**: 70% train, 15% val, 15% test

## Requirements

```bash
pip install torch torchvision
pip install albumentations
pip install pillow numpy tqdm
```

## Notes

- Void pixels (class 255) are automatically ignored in loss calculation
- Class weights help handle class imbalance
- Using Albumentations for transforms ensures both image and mask are transformed identically
- Dataset statistics computed from training set only
- 11-class grouping follows MATLAB's SegNet methodology for better training
