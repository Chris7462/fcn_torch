# FCN_Torch: Semantic Segmentation with PyTorch

PyTorch implementation of Fully Convolutional Networks (FCN) for semantic segmentation on CamVid dataset.

## Features

- **Registry System** - Config-driven model/dataset/optimizer building
- **Modular Design** - Separate backbone, decoder, and runner components
- **VGG16 Backbone** - Using torchvision's pretrained weights (extensible to ResNet)
- **CamVid Dataset** - 11-class semantic segmentation
- **Training/Validation/Testing** - Unified entry point with logging

## Project Structure
```
fcn_torch/
├── main.py                   # Entry point (train/val/test)
├── configs/
│   └── camvid.py             # Training configuration
├── models/
│   ├── fcn.py                # FCN model (registered)
│   ├── backbones/            # Backbone networks
│   │   └── vgg.py            # VGG16 backbone
│   └── decoders/             # Decoder heads
│       └── fcn_head.py       # FCN decoder (TorchVision style)
├── datasets/
│   ├── camvid.py             # CamVid dataset (registered)
│   ├── camvid_dataset.py     # PyTorch Dataset class
│   └── registry.py           # Dataset registry
├── runner/
│   ├── runner.py             # Training/validation/testing logic
│   ├── optimizer.py          # Optimizer builder
│   ├── scheduler.py          # LR scheduler builder
│   ├── recorder.py           # Logging and metrics
│   └── net_utils.py          # Model save/load
├── utils/
│   ├── config.py             # Config loader
│   ├── registry.py           # Registry system
│   └── metrics.py            # IoU and pixel accuracy
└── tools/
    └── prepare_camvid.py     # Dataset preparation script
```

## Data Download

Download the CamVid dataset from: [CamVid](https://datasets.cms.waikato.ac.nz/ufdl/camvid/)

Required files:
- `701_StillsRaw_full/` - Raw RGB images
- `LabeledApproved_full/` - RGB color-coded label masks
- `label_colors.txt` - RGB to class name mapping

## Dataset Structure
```
CamVid/
├── 701_StillsRaw_full/          # Raw RGB images
├── LabeledApproved_full/         # RGB color-coded label masks (_L.png)
├── label_colors.txt              # RGB to class name mapping
└── splits/                       # Generated by prepare script
    ├── train.txt
    ├── val.txt
    ├── test.txt
    └── dataset_info.json
```

## CamVid 11-Class Grouping

Following MATLAB's SegNet methodology, the original 32 CamVid classes are grouped into 11 classes:

1. **Sky** - Sky
2. **Building** - Bridge, Building, Wall, Tunnel, Archway
3. **Pole** - Column_Pole, TrafficCone
4. **Road** - Road, LaneMkgsDriv, LaneMkgsNonDriv
5. **Pavement** - Sidewalk, ParkingBlock, RoadShoulder
6. **Tree** - Tree, VegetationMisc
7. **SignSymbol** - SignSymbol, Misc_Text, TrafficLight
8. **Fence** - Fence
9. **Car** - Car, SUVPickupTruck, Truck_Bus, Train, OtherMoving
10. **Pedestrian** - Pedestrian, Child, CartLuggagePram, Animal
11. **Bicyclist** - Bicyclist, MotorcycleScooter

**Note:** The **Void** class is excluded from the 11 classes and remains as `ignore_index=255`.

This grouping provides better class balance and improved training, especially for underrepresented classes.

## Quick Start

### 1. Installation
```bash
# Install dependencies
pip install torch torchvision
pip install albumentations
pip install pillow numpy tqdm matplotlib
```

### 2. Dataset Preparation
```bash
# Create symbolic link to CamVid dataset
ln -s /path/to/CamVid .

# Prepare dataset (creates splits and computes statistics)
python tools/prepare_camvid.py
```

This will create:
- `CamVid/splits/train.txt` - Training image list (70%)
- `CamVid/splits/val.txt` - Validation image list (15%)
- `CamVid/splits/test.txt` - Test image list (15%)
- `CamVid/splits/dataset_info.json` - Metadata (classes, statistics, weights)

### 3. Training
```bash
# Train from scratch
python main.py configs/camvid.py

# Resume training
python main.py configs/camvid.py --load_from work_dirs/CamVid/TIMESTAMP/ckpt/best.pth
```

### 4. Validation
```bash
# Validate a trained model
python main.py configs/camvid.py --validate --load_from work_dirs/CamVid/TIMESTAMP/ckpt/best.pth
```

### 5. Testing
```bash
# Run inference and save predictions
python main.py configs/camvid.py --test --load_from work_dirs/CamVid/TIMESTAMP/ckpt/best.pth
```

## Output Structure
```
work_dirs/
└── CamVid/
    └── YYYYMMDD_HHMMSS/
        ├── log.txt                    # Training log
        ├── ckpt/
        │   ├── best.pth              # Best model checkpoint
        │   ├── last.pth              # Latest checkpoint
        │   └── epoch_N.pth           # Periodic checkpoints
        ├── plots/
        │   └── training_history.png  # Loss/accuracy curves
        ├── predictions/              # Test predictions (RGB masks)
        └── visualizations/           # Side-by-side comparisons
```

## Configuration

Edit `configs/camvid.py` to customize:
```python
# Model configuration
net = dict(type='FCNs')
backbone = dict(type='VGG16', pretrained=True)
decoder = dict(type='FCNHead')

# Training hyperparameters
batch_size = 16
epochs = 200
img_height = 352
img_width = 480

# Optimizer
optimizer = dict(
    type='sgd',
    lr=0.001,
    weight_decay=5e-4,
    momentum=0.9
)

# Learning rate scheduler
scheduler = dict(
    type='StepLR',
    step_size=50,
    gamma=0.5
)
```

## Dataset Features

### Data Augmentation (Training)
- Resize to 480×360
- Center crop to 480×352 (divisible by 32 for FCN)
- Random horizontal flip (p=0.5)
- Color jittering (brightness, contrast, saturation, hue)
- Normalization (mean/std computed from training set)

### Validation/Test
- Resize to 480×360
- Center crop to 480×352
- Normalization only (no augmentation)

### Class Handling
- 11 classes (grouped from original 32)
- Void class (RGB: 0,0,0) mapped to index 255
- Class weights computed using Median Frequency Balancing
- Automatic RGB to class index conversion during loading

## Model Architecture

- **Backbone**: VGG16 (pretrained on ImageNet via torchvision)
- **Decoder**: FCN-32s (simplified, TorchVision style, no skip connections)
- **Output**: Per-pixel classification with bilinear upsampling

## Extending the Framework

### Add New Backbone (e.g., ResNet50)

1. Create `models/backbones/resnet.py`:
```python
from .registry import BACKBONES

@BACKBONES.register_module
class ResNet50(nn.Module):
    def __init__(self, pretrained=True):
        # Implementation
        self.out_channels = 2048
```

2. Update config:
```python
backbone = dict(type='ResNet50', pretrained=True)
```

### Add New Dataset (e.g., Cityscapes)

1. Create `datasets/cityscapes.py`:
```python
from .registry import DATASETS

@DATASETS.register_module
class Cityscapes(BaseDataset):
    # Implementation
```

2. Create `configs/cityscapes.py` with dataset configuration

3. Run training:
```bash
python main.py configs/cityscapes.py
```

## Dataset Statistics

- **Total images**: 701 images
- **Train/Val/Test split**: 70% / 15% / 15%
- **Image size**: 480×352 (resized from original, divisible by 32)
- **Format**: RGB images + RGB color-coded masks
- **Classes**: 11 classes + 1 void class (ignore_index=255)

## Expected Results

Example metrics on CamVid validation set:
- Validation mIoU: ~0.65-0.70
- Pixel Accuracy: ~0.90-0.92

*Note: Results may vary depending on hyperparameters and training duration.*

## Requirements
```bash
torch>=1.9.0
torchvision>=0.10.0
albumentations>=1.0.0
pillow>=8.0.0
numpy>=1.19.0
tqdm>=4.60.0
matplotlib>=3.3.0
```

## License

Apache License 2.0

## Acknowledgments

- FCN implementation based on [TorchVision](https://github.com/pytorch/vision)
- CamVid dataset: [University of Cambridge](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/)
