# CamVid Dataset PyTorch DataLoader

Complete PyTorch dataloader implementation for the CamVid semantic segmentation dataset.

## Data Download
You can find the raw images and labeled images at here: [CamVid](https://datasets.cms.waikato.ac.nz/ufdl/camvid/)

## Dataset Structure

```
/data/CamVid/
├── 701_StillsRaw_full/          # Raw RGB images
├── LabeledApproved_full/         # RGB color-coded label masks (_L.png)
├── label_colors.txt              # RGB to class name mapping
└── splits/                       # Generated by prepare script
    ├── train.txt
    ├── val.txt
    ├── test.txt
    └── dataset_info.json
```

## Files Overview

1. **prepare_camvid_data.py** - Data preparation script
   - Scans and pairs images with labels
   - Creates train/val/test splits (70/15/15)
   - Computes dataset statistics (mean, std)
   - Computes class distribution and weights

2. **camvid_dataset.py** - PyTorch Dataset class
   - Loads images and converts RGB masks to class indices
   - Applies data augmentation (training) or just normalization (val/test)
   - Handles void/ignore class (index 255)

3. **create_dataloaders.py** - DataLoader creation
   - Creates train/val/test dataloaders
   - Configurable batch size, workers, image size
   - Returns class weights for loss function

4. **example_usage.py** - Complete usage example
   - Shows how to use dataloaders in training

## Usage

### Step 1: Prepare the Dataset
Symbolic link the CamVid folder to this folder. The CamVid folder most contains:
* 701_StillsRaw_full: The raw images
* LabeledApproved_full: The labeled images
* label_colors.txt: The classname mapping

```bash
ln -s CamVid .
python prepare_camvid_data.py
```

This will create:
- `splits/train.txt` - List of training image filenames
- `splits/val.txt` - List of validation image filenames
- `splits/test.txt` - List of test image filenames
- `splits/dataset_info.json` - Metadata (classes, stats, weights)

### Step 2: Use in Your Training Script

```python
from create_dataloaders import create_dataloaders
import torch.nn as nn

# Create dataloaders
dataloaders = create_dataloaders(
    raw_image_dir='/data/CamVid/701_StillsRaw_full',
    label_dir='/data/CamVid/LabeledApproved_full',
    splits_dir='/data/CamVid/splits',
    dataset_info_path='/data/CamVid/splits/dataset_info.json',
    batch_size=8,
    num_workers=4,
    target_size=(480, 360)
)

train_loader = dataloaders['train']
val_loader = dataloaders['val']
test_loader = dataloaders['test']
class_weights = dataloaders['class_weights']
num_classes = dataloaders['num_classes']  # 32
ignore_index = dataloaders['ignore_index']  # 255

# Setup loss with class weights
criterion = nn.CrossEntropyLoss(
    weight=class_weights,
    ignore_index=ignore_index
)

# Training loop
for batch in train_loader:
    images = batch['image']  # [B, 3, 360, 480]
    masks = batch['mask']    # [B, 360, 480]
    filenames = batch['filename']

    # Your model forward pass
    outputs = model(images)  # [B, num_classes, 360, 480]
    loss = criterion(outputs, masks)
```

## Key Features

### Data Augmentation (Training)
- Resize to 480x360
- Random horizontal flip
- Color jittering (brightness, contrast, saturation, hue)
- Normalization

### Validation/Test
- Resize to 480x360
- Normalization only (no augmentation)

### Class Handling
- 32 classes total (31 semantic + 1 void)
- Void class (RGB: 0,0,0) mapped to index 255
- Class weights computed for imbalanced classes

### RGB to Index Conversion
- Automatically converts RGB color masks to class indices
- Handles on-the-fly during loading

## Dataset Info

- **Total classes**: 32 (including Void)
- **Image size**: 960x720 (original) → 480x360 (resized for training)
- **Format**: RGB images + RGB color-coded masks
- **Split**: 70% train, 15% val, 15% test

## Classes

See `label_colors.txt` for the complete list. Main classes include:
- Sky, Building, Road, Sidewalk, Tree
- Car, Truck_Bus, Pedestrian, Bicyclist
- Sign, Fence, Pole, Traffic Light
- And more...

## Requirements

```bash
pip install torch torchvision
pip install albumentations
pip install pillow numpy tqdm
```

## Notes

- Void pixels (class 255) are automatically ignored in loss calculation
- Class weights help handle class imbalance (sky, road > pedestrian, bicyclist)
- Using Albumentations for transforms ensures both image and mask are transformed identically
- Dataset statistics computed from training set only
